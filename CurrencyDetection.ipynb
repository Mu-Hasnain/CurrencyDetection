{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mu-Hasnain/CurrencyDetection/blob/main/CurrencyDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5irVEgyXwL7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8a32f2-bbbd-4059-9ee4-ed39c4f65fc4"
      },
      "source": [
        "!pip install gtts"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gtts) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gtts) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from gtts) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gtts) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gtts) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gtts) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gtts) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymDZNkRykNlZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from gtts import gTTS\n",
        "import cv2 \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from IPython.display import Audio\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras import models"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKxXUgdjkck4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "406bcf61-007f-4883-fd07-928bcc27dd89"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 6.0 kB/s \n",
            "\u001b[?25hCollecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 59.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.47.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.26.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (14.0.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 70.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (4.1.1)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 19.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires keras<2.9,>=2.8.0rc0, but you have keras 2.9.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.9.1 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 2.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed flatbuffers-1.12 gast-0.4.0 keras-2.9.0 tensorboard-2.9.1 tensorflow-estimator-2.9.0 tensorflow-gpu-2.9.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "gast",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytQWpXLdk1GI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7aea03a-6b54-4e2c-b82c-bec7f0a7f3bf"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul 26 18:15:13 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTgV15M9lNFf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3a4e69ec-3d78-4d0b-c3a3-528b13eaa270"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYZuCmIPlPtB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ff05374-5518-44d0-88b6-b5b6671588b7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSD9pVyVmRHx"
      },
      "source": [
        "train=\"/content/drive/MyDrive/train\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTSB2v4qmpq-"
      },
      "source": [
        "test=\"/content/drive/MyDrive/dataset/Testdata\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2wamqyGnK5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "81048f19-6a22-467f-a165-d6c69e580450"
      },
      "source": [
        "train"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/train'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEnBwmY_ncjz"
      },
      "source": [
        "ImageDataGenerator = tf.keras.preprocessing.image.ImageDataGenerator"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VZLqe-2niEZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6cee6a-1e7f-4918-c8d4-8327e6d85911"
      },
      "source": [
        "TRAINING_DIR = \"/content/drive/MyDrive/dataset/Traindata\"\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.,shear_range=0.2,\n",
        "                                       zoom_range=0.4,\n",
        "                                       horizontal_flip=True, \n",
        "                                         )\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
        "                                                    batch_size=30,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(256, 256))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 700 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVBFY7zm7qB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0cd4ce-059c-4c74-e0ad-cb54e80f5f22"
      },
      "source": [
        "VALIDATION_DIR = \"/content/drive/MyDrive/dataset/Testdata\"\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0/255.,shear_range=0.2,\n",
        "                                       zoom_range=0.6,\n",
        "                                       horizontal_flip=True)\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
        "                                                              batch_size=30,\n",
        "                                                              class_mode='binary',\n",
        "                                                              target_size=(256, 256))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 703 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xajynrg2C6uV"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(.5, input_shape=(256,)),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(.5, input_shape=(256,)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Dropout(.5, input_shape=(256,)), \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(8, activation='softmax')])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Pwxm5g8I_M"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tgm9zwu58Pzn",
        "outputId": "47c75474-de2d-44ff-996d-2b05042b61bd"
      },
      "source": [
        "model.summary()\n",
        "history = model.fit_generator(train_generator,\n",
        "                              epochs=250,\n",
        "                              verbose=1,\n",
        "                              validation_data=validation_generator)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 127, 127, 16)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 127, 127, 16)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 62, 62, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 62, 62, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 30, 30, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 57600)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               29491712  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 4104      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,519,400\n",
            "Trainable params: 29,519,400\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa745ec0b90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fa745ec0b90> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "24/24 [==============================] - ETA: 0s - loss: 4.2604 - accuracy: 0.1571 WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa790ee4cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fa790ee4cb0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "24/24 [==============================] - 497s 21s/step - loss: 4.2604 - accuracy: 0.1571 - val_loss: 2.0752 - val_accuracy: 0.1422\n",
            "Epoch 2/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 2.0560 - accuracy: 0.1371 - val_loss: 2.0565 - val_accuracy: 0.1451\n",
            "Epoch 3/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 1.9937 - accuracy: 0.1500 - val_loss: 1.9756 - val_accuracy: 0.2048\n",
            "Epoch 4/250\n",
            "24/24 [==============================] - 28s 1s/step - loss: 1.9035 - accuracy: 0.1886 - val_loss: 1.8915 - val_accuracy: 0.2845\n",
            "Epoch 5/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 1.5824 - accuracy: 0.3700 - val_loss: 1.4094 - val_accuracy: 0.4225\n",
            "Epoch 6/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 1.0294 - accuracy: 0.5814 - val_loss: 0.9942 - val_accuracy: 0.6145\n",
            "Epoch 7/250\n",
            "24/24 [==============================] - 28s 1s/step - loss: 0.8233 - accuracy: 0.6343 - val_loss: 0.9533 - val_accuracy: 0.5903\n",
            "Epoch 8/250\n",
            "24/24 [==============================] - 28s 1s/step - loss: 0.7355 - accuracy: 0.7000 - val_loss: 1.1214 - val_accuracy: 0.5121\n",
            "Epoch 9/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.5752 - accuracy: 0.7357 - val_loss: 0.7202 - val_accuracy: 0.6814\n",
            "Epoch 10/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.5421 - accuracy: 0.7529 - val_loss: 0.9588 - val_accuracy: 0.5690\n",
            "Epoch 11/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.4548 - accuracy: 0.7800 - val_loss: 0.9102 - val_accuracy: 0.6273\n",
            "Epoch 12/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.5346 - accuracy: 0.7586 - val_loss: 1.4118 - val_accuracy: 0.5192\n",
            "Epoch 13/250\n",
            "24/24 [==============================] - 28s 1s/step - loss: 0.5320 - accuracy: 0.7643 - val_loss: 0.5643 - val_accuracy: 0.8009\n",
            "Epoch 14/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.4059 - accuracy: 0.8186 - val_loss: 0.6512 - val_accuracy: 0.7212\n",
            "Epoch 15/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.2883 - accuracy: 0.8857 - val_loss: 0.5990 - val_accuracy: 0.7041\n",
            "Epoch 16/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.2620 - accuracy: 0.8943 - val_loss: 0.6406 - val_accuracy: 0.7553\n",
            "Epoch 17/250\n",
            "24/24 [==============================] - 28s 1s/step - loss: 0.2097 - accuracy: 0.9271 - val_loss: 1.1822 - val_accuracy: 0.5804\n",
            "Epoch 18/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.1445 - accuracy: 0.9600 - val_loss: 0.4949 - val_accuracy: 0.8122\n",
            "Epoch 19/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0904 - accuracy: 0.9729 - val_loss: 0.4720 - val_accuracy: 0.8137\n",
            "Epoch 20/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0498 - accuracy: 0.9843 - val_loss: 0.4396 - val_accuracy: 0.8634\n",
            "Epoch 21/250\n",
            "24/24 [==============================] - 28s 1s/step - loss: 0.0287 - accuracy: 0.9929 - val_loss: 0.2505 - val_accuracy: 0.9175\n",
            "Epoch 22/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0744 - accuracy: 0.9814 - val_loss: 0.6008 - val_accuracy: 0.7425\n",
            "Epoch 23/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0442 - accuracy: 0.9886 - val_loss: 0.2012 - val_accuracy: 0.9459\n",
            "Epoch 24/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0285 - accuracy: 0.9914 - val_loss: 0.2380 - val_accuracy: 0.9161\n",
            "Epoch 25/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0328 - accuracy: 0.9929 - val_loss: 0.3485 - val_accuracy: 0.8791\n",
            "Epoch 26/250\n",
            "24/24 [==============================] - 28s 1s/step - loss: 0.1473 - accuracy: 0.9571 - val_loss: 0.2695 - val_accuracy: 0.9104\n",
            "Epoch 27/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.1535 - accuracy: 0.9357 - val_loss: 0.4595 - val_accuracy: 0.8336\n",
            "Epoch 28/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0224 - accuracy: 0.9957 - val_loss: 0.2024 - val_accuracy: 0.9445\n",
            "Epoch 29/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2585 - val_accuracy: 0.9175\n",
            "Epoch 30/250\n",
            "24/24 [==============================] - 28s 1s/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9331\n",
            "Epoch 31/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0196 - accuracy: 0.9943 - val_loss: 0.2400 - val_accuracy: 0.9132\n",
            "Epoch 32/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0502 - accuracy: 0.9814 - val_loss: 0.7178 - val_accuracy: 0.7269\n",
            "Epoch 33/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0581 - accuracy: 0.9800 - val_loss: 0.5715 - val_accuracy: 0.7710\n",
            "Epoch 34/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0155 - accuracy: 0.9943 - val_loss: 0.2106 - val_accuracy: 0.9331\n",
            "Epoch 35/250\n",
            "24/24 [==============================] - 28s 1s/step - loss: 0.0146 - accuracy: 0.9929 - val_loss: 0.3054 - val_accuracy: 0.9075\n",
            "Epoch 36/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0131 - accuracy: 0.9943 - val_loss: 0.1116 - val_accuracy: 0.9716\n",
            "Epoch 37/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9659\n",
            "Epoch 38/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9616\n",
            "Epoch 39/250\n",
            "24/24 [==============================] - 28s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9531\n",
            "Epoch 40/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0617 - val_accuracy: 0.9858\n",
            "Epoch 41/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 7.2870e-04 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9573\n",
            "Epoch 42/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9730\n",
            "Epoch 43/250\n",
            "24/24 [==============================] - 28s 1s/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.3201 - val_accuracy: 0.8649\n",
            "Epoch 44/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.1146 - val_accuracy: 0.9673\n",
            "Epoch 45/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 9.4657e-04 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9716\n",
            "Epoch 46/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 3.0126e-04 - accuracy: 1.0000 - val_loss: 0.0673 - val_accuracy: 0.9787\n",
            "Epoch 47/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 5.6907e-04 - accuracy: 1.0000 - val_loss: 0.0728 - val_accuracy: 0.9772\n",
            "Epoch 48/250\n",
            "24/24 [==============================] - 28s 1s/step - loss: 4.0664e-04 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9701\n",
            "Epoch 49/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 8.6787e-04 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9716\n",
            "Epoch 50/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9701\n",
            "Epoch 51/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 7.9648e-04 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9616\n",
            "Epoch 52/250\n",
            "24/24 [==============================] - 28s 1s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1566 - val_accuracy: 0.9531\n",
            "Epoch 53/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9602\n",
            "Epoch 54/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 4.1871e-04 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9744\n",
            "Epoch 55/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 0.9801\n",
            "Epoch 56/250\n",
            "24/24 [==============================] - 28s 1s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2615 - val_accuracy: 0.9018\n",
            "Epoch 57/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.1911 - val_accuracy: 0.9587\n",
            "Epoch 58/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9616\n",
            "Epoch 59/250\n",
            "24/24 [==============================] - 27s 1s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9246\n",
            "Epoch 60/250\n",
            "24/24 [==============================] - 28s 1s/step - loss: 4.1817e-04 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9744\n",
            "Epoch 61/250\n",
            "24/24 [==============================] - 29s 1s/step - loss: 4.9895e-04 - accuracy: 1.0000 - val_loss: 0.0470 - val_accuracy: 0.9858\n",
            "Epoch 62/250\n",
            "24/24 [==============================] - 29s 1s/step - loss: 5.0476e-04 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9673\n",
            "Epoch 63/250\n",
            "24/24 [==============================] - 30s 1s/step - loss: 1.3379e-04 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 0.9787\n",
            "Epoch 64/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.4114e-04 - accuracy: 1.0000 - val_loss: 0.0750 - val_accuracy: 0.9730\n",
            "Epoch 65/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 4.5210e-04 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9758\n",
            "Epoch 66/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.2192e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9673\n",
            "Epoch 67/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.9621e-04 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9801\n",
            "Epoch 68/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 6.7374e-05 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9744\n",
            "Epoch 69/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.3987e-04 - accuracy: 1.0000 - val_loss: 0.1087 - val_accuracy: 0.9687\n",
            "Epoch 70/250\n",
            "24/24 [==============================] - 30s 1s/step - loss: 1.4632e-04 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9616\n",
            "Epoch 71/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.5520e-04 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 0.9602\n",
            "Epoch 72/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.4112e-04 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9630\n",
            "Epoch 73/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.6450e-04 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9716\n",
            "Epoch 74/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2304 - val_accuracy: 0.9431\n",
            "Epoch 75/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 8.4676e-04 - accuracy: 1.0000 - val_loss: 0.2462 - val_accuracy: 0.9047\n",
            "Epoch 76/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9701\n",
            "Epoch 77/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9673\n",
            "Epoch 78/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 2.4159e-04 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9772\n",
            "Epoch 79/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.6204e-04 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9673\n",
            "Epoch 80/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 8.2664e-05 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9787\n",
            "Epoch 81/250\n",
            "24/24 [==============================] - 35s 1s/step - loss: 3.6286e-04 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9488\n",
            "Epoch 82/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0873 - accuracy: 0.9829 - val_loss: 0.4900 - val_accuracy: 0.8777\n",
            "Epoch 83/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.5481 - accuracy: 0.8300 - val_loss: 0.3694 - val_accuracy: 0.9303\n",
            "Epoch 84/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0942 - accuracy: 0.9757 - val_loss: 0.2370 - val_accuracy: 0.9104\n",
            "Epoch 85/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 0.0157 - accuracy: 0.9986 - val_loss: 0.1256 - val_accuracy: 0.9659\n",
            "Epoch 86/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0096 - accuracy: 0.9957 - val_loss: 0.0848 - val_accuracy: 0.9730\n",
            "Epoch 87/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9844\n",
            "Epoch 88/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 0.0151 - accuracy: 0.9929 - val_loss: 0.0635 - val_accuracy: 0.9815\n",
            "Epoch 89/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9872\n",
            "Epoch 90/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0030 - accuracy: 0.9986 - val_loss: 0.0554 - val_accuracy: 0.9844\n",
            "Epoch 91/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0527 - val_accuracy: 0.9844\n",
            "Epoch 92/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9687\n",
            "Epoch 93/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 8.6235e-04 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9886\n",
            "Epoch 94/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 0.9886\n",
            "Epoch 95/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 9.0544e-04 - accuracy: 1.0000 - val_loss: 0.0291 - val_accuracy: 0.9943\n",
            "Epoch 96/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.5323e-04 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9787\n",
            "Epoch 97/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 9.6918e-04 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9943\n",
            "Epoch 98/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9858\n",
            "Epoch 99/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9744\n",
            "Epoch 100/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 7.1472e-04 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9929\n",
            "Epoch 101/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.1009e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9943\n",
            "Epoch 102/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 9.6322e-04 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 0.9858\n",
            "Epoch 103/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0066 - accuracy: 0.9957 - val_loss: 0.0713 - val_accuracy: 0.9772\n",
            "Epoch 104/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9900\n",
            "Epoch 105/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 0.0076 - accuracy: 0.9957 - val_loss: 0.3036 - val_accuracy: 0.8834\n",
            "Epoch 106/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.3755 - accuracy: 0.9100 - val_loss: 0.6840 - val_accuracy: 0.7312\n",
            "Epoch 107/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0931 - accuracy: 0.9700 - val_loss: 0.2496 - val_accuracy: 0.9118\n",
            "Epoch 108/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 0.0250 - accuracy: 0.9929 - val_loss: 0.0696 - val_accuracy: 0.9872\n",
            "Epoch 109/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9787\n",
            "Epoch 110/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9915\n",
            "Epoch 111/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0390 - val_accuracy: 0.9929\n",
            "Epoch 112/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 4.2986e-04 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 0.9886\n",
            "Epoch 113/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 4.0947e-04 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9957\n",
            "Epoch 114/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.0772e-04 - accuracy: 1.0000 - val_loss: 0.0471 - val_accuracy: 0.9886\n",
            "Epoch 115/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 3.2552e-04 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9972\n",
            "Epoch 116/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.7887e-04 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9972\n",
            "Epoch 117/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.9378e-04 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9929\n",
            "Epoch 118/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 3.7472e-04 - accuracy: 1.0000 - val_loss: 0.0301 - val_accuracy: 0.9957\n",
            "Epoch 119/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.2550e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9943\n",
            "Epoch 120/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.5517e-04 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9929\n",
            "Epoch 121/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.2840e-04 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9957\n",
            "Epoch 122/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 2.6195e-04 - accuracy: 1.0000 - val_loss: 0.0357 - val_accuracy: 0.9957\n",
            "Epoch 123/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.6271e-04 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9929\n",
            "Epoch 124/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.5899e-04 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9957\n",
            "Epoch 125/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 1.6953e-04 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9943\n",
            "Epoch 126/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.2018e-04 - accuracy: 1.0000 - val_loss: 0.0339 - val_accuracy: 0.9929\n",
            "Epoch 127/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 9.5085e-05 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9943\n",
            "Epoch 128/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 1.2675e-04 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 0.9943\n",
            "Epoch 129/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.3106e-04 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 0.9915\n",
            "Epoch 130/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.5293e-04 - accuracy: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9915\n",
            "Epoch 131/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.0055e-04 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9929\n",
            "Epoch 132/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 1.8778e-04 - accuracy: 1.0000 - val_loss: 0.0132 - val_accuracy: 0.9972\n",
            "Epoch 133/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.8168e-04 - accuracy: 1.0000 - val_loss: 0.0367 - val_accuracy: 0.9929\n",
            "Epoch 134/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.3222e-04 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9900\n",
            "Epoch 135/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 7.7990e-05 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9943\n",
            "Epoch 136/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.5086e-04 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 0.9900\n",
            "Epoch 137/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.1482e-04 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9915\n",
            "Epoch 138/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.0187e-04 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9972\n",
            "Epoch 139/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 5.7544e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9886\n",
            "Epoch 140/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.8289e-04 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9886\n",
            "Epoch 141/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.5049e-04 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9972\n",
            "Epoch 142/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 8.3672e-05 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9972\n",
            "Epoch 143/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 6.1468e-05 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9929\n",
            "Epoch 144/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 6.1963e-05 - accuracy: 1.0000 - val_loss: 0.0312 - val_accuracy: 0.9943\n",
            "Epoch 145/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 5.8440e-05 - accuracy: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9900\n",
            "Epoch 146/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 5.4701e-05 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9957\n",
            "Epoch 147/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 4.7480e-05 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9943\n",
            "Epoch 148/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 7.2264e-05 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9929\n",
            "Epoch 149/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 6.2938e-05 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9972\n",
            "Epoch 150/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 5.1789e-05 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 0.9957\n",
            "Epoch 151/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 5.2071e-05 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9900\n",
            "Epoch 152/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 6.2697e-05 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9972\n",
            "Epoch 153/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 8.8442e-05 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 0.9957\n",
            "Epoch 154/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.0969e-04 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9986\n",
            "Epoch 155/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 7.6337e-05 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9957\n",
            "Epoch 156/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 7.1114e-05 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9943\n",
            "Epoch 157/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.4940e-05 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9957\n",
            "Epoch 158/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 4.2478e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9972\n",
            "Epoch 159/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 8.2392e-05 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9957\n",
            "Epoch 160/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 4.0786e-05 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9972\n",
            "Epoch 161/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 6.3103e-05 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9972\n",
            "Epoch 162/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 6.2449e-05 - accuracy: 1.0000 - val_loss: 0.0253 - val_accuracy: 0.9929\n",
            "Epoch 163/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.2270e-05 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9972\n",
            "Epoch 164/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 4.2057e-05 - accuracy: 1.0000 - val_loss: 0.0195 - val_accuracy: 0.9972\n",
            "Epoch 165/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 5.2441e-05 - accuracy: 1.0000 - val_loss: 0.0181 - val_accuracy: 0.9972\n",
            "Epoch 166/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 5.6515e-05 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9957\n",
            "Epoch 167/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.5541e-04 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9943\n",
            "Epoch 168/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 8.6290e-05 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9972\n",
            "Epoch 169/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 8.4035e-05 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9972\n",
            "Epoch 170/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 9.6981e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9929\n",
            "Epoch 171/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 2.5200e-05 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 0.9943\n",
            "Epoch 172/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 1.3368e-04 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 0.9986\n",
            "Epoch 173/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.7026e-04 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9929\n",
            "Epoch 174/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.4088e-04 - accuracy: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9972\n",
            "Epoch 175/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 7.6014e-05 - accuracy: 1.0000 - val_loss: 0.0174 - val_accuracy: 0.9957\n",
            "Epoch 176/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.8298e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9986\n",
            "Epoch 177/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.9835e-05 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9915\n",
            "Epoch 178/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 2.0085e-05 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9915\n",
            "Epoch 179/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.4823e-05 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9943\n",
            "Epoch 180/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 4.8249e-05 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 0.9957\n",
            "Epoch 181/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 2.7371e-05 - accuracy: 1.0000 - val_loss: 0.0194 - val_accuracy: 0.9972\n",
            "Epoch 182/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.1751e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9986\n",
            "Epoch 183/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.4654e-05 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9929\n",
            "Epoch 184/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.5233e-05 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9943\n",
            "Epoch 185/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 3.7288e-05 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9957\n",
            "Epoch 186/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.2306e-05 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9943\n",
            "Epoch 187/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 3.9037e-05 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 0.9986\n",
            "Epoch 188/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.9218e-05 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9972\n",
            "Epoch 189/250\n",
            "24/24 [==============================] - 31s 1s/step - loss: 3.8128e-05 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9929\n",
            "Epoch 190/250\n",
            "24/24 [==============================] - 30s 1s/step - loss: 9.0439e-05 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9943\n",
            "Epoch 191/250\n",
            "24/24 [==============================] - 31s 1s/step - loss: 1.7162e-05 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9929\n",
            "Epoch 192/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.5298e-05 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 0.9986\n",
            "Epoch 193/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 2.0283e-04 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9915\n",
            "Epoch 194/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 5.5381e-05 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9943\n",
            "Epoch 195/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 3.9000e-05 - accuracy: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9929\n",
            "Epoch 196/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.6777e-05 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9915\n",
            "Epoch 197/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.2265e-05 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9943\n",
            "Epoch 198/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 1.6008e-05 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9900\n",
            "Epoch 199/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 4.1015e-05 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9957\n",
            "Epoch 200/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.2228e-05 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9943\n",
            "Epoch 201/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 2.0454e-05 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9972\n",
            "Epoch 202/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.8334e-05 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9972\n",
            "Epoch 203/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 4.3339e-05 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9957\n",
            "Epoch 204/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 2.2163e-05 - accuracy: 1.0000 - val_loss: 0.0345 - val_accuracy: 0.9943\n",
            "Epoch 205/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.5503e-05 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9929\n",
            "Epoch 206/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 1.2617e-05 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9957\n",
            "Epoch 207/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 9.9539e-06 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9986\n",
            "Epoch 208/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 1.7973e-05 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9900\n",
            "Epoch 209/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 2.0146e-05 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9915\n",
            "Epoch 210/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 1.1924e-05 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 211/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 1.6158e-05 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 0.9943\n",
            "Epoch 212/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 8.9751e-06 - accuracy: 1.0000 - val_loss: 0.0120 - val_accuracy: 0.9972\n",
            "Epoch 213/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.2932e-05 - accuracy: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9943\n",
            "Epoch 214/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 1.9184e-05 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9986\n",
            "Epoch 215/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 8.4604e-06 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 216/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 5.8189e-06 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9929\n",
            "Epoch 217/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 1.1717e-05 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 0.9972\n",
            "Epoch 218/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 8.1371e-06 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9957\n",
            "Epoch 219/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 4.8123e-06 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9943\n",
            "Epoch 220/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 2.4276e-05 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 0.9957\n",
            "Epoch 221/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.5920e-05 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9957\n",
            "Epoch 222/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.9961e-06 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9972\n",
            "Epoch 223/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.9419e-06 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9957\n",
            "Epoch 224/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 6.3945e-06 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 0.9943\n",
            "Epoch 225/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 7.6217e-06 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 0.9943\n",
            "Epoch 226/250\n",
            "24/24 [==============================] - 31s 1s/step - loss: 4.9643e-06 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9943\n",
            "Epoch 227/250\n",
            "24/24 [==============================] - 31s 1s/step - loss: 3.7919e-06 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 0.9915\n",
            "Epoch 228/250\n",
            "24/24 [==============================] - 30s 1s/step - loss: 4.9686e-06 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9972\n",
            "Epoch 229/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 1.5872e-05 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9943\n",
            "Epoch 230/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 8.4472e-06 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9972\n",
            "Epoch 231/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 6.1983e-06 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9957\n",
            "Epoch 232/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 6.9404e-06 - accuracy: 1.0000 - val_loss: 0.0652 - val_accuracy: 0.9886\n",
            "Epoch 233/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 9.9405e-06 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9957\n",
            "Epoch 234/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 7.0418e-06 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9972\n",
            "Epoch 235/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 7.9486e-06 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9915\n",
            "Epoch 236/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 1.1661e-05 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9900\n",
            "Epoch 237/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 1.2073e-05 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9957\n",
            "Epoch 238/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 1.5816e-05 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9929\n",
            "Epoch 239/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 3.9242e-05 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9957\n",
            "Epoch 240/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 7.4650e-06 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9915\n",
            "Epoch 241/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 4.9282e-06 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 0.9957\n",
            "Epoch 242/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 7.0843e-06 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 0.9929\n",
            "Epoch 243/250\n",
            "24/24 [==============================] - 34s 1s/step - loss: 2.6083e-05 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 0.9929\n",
            "Epoch 244/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 4.3135e-06 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9943\n",
            "Epoch 245/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 3.4270e-06 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9957\n",
            "Epoch 246/250\n",
            "24/24 [==============================] - 36s 2s/step - loss: 5.9846e-06 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 0.9957\n",
            "Epoch 247/250\n",
            "24/24 [==============================] - 36s 2s/step - loss: 3.3154e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9900\n",
            "Epoch 248/250\n",
            "24/24 [==============================] - 33s 1s/step - loss: 1.2340e-05 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9972\n",
            "Epoch 249/250\n",
            "24/24 [==============================] - 36s 2s/step - loss: 9.9866e-06 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9929\n",
            "Epoch 250/250\n",
            "24/24 [==============================] - 32s 1s/step - loss: 3.1789e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCPTE7QWC4hr"
      },
      "source": [
        "#model.save('CNNmodel.h5')\n",
        "model.save('/content/drive/MyDrive/Currency/CurrencyDetectionModel.h5')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jouT6x0bRxak"
      },
      "source": [
        "import matplotlib.image  as mpimg"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgKfA8c7R2lx"
      },
      "source": [
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMr3tAQGR6pZ"
      },
      "source": [
        " epochs=range(len(acc)) # Get number of epochs"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fofet8ZvR96b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "5bd54ac6-a2d2-4c40-c006-292eb76a632a"
      },
      "source": [
        "# Plot training and validation accuracy per epoch\n",
        "# #------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcYAAAEICAYAAADFgFTtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xcddn38c+1JdndbHqFdEJoCSZAIIAaIqC0W5GiiEgVUeBG8XksiHCLIjzojYAdRSkKIh2RJigiNRACgRQ6aSTZ9LYtm929nj9+5+yc2cxsNtsm2fm+X695zZkzZ878zpnd+c71O83cHREREQkKct0AERGRHYmCUUREJEHBKCIikqBgFBERSVAwioiIJCgYRUREEhSMIttgZo+Z2ZkdPW0umdlCMzuyE+brZrZ7NHyjmV3emmnb8D6nmdkTbW2nSEtMxzFKd2RmlYmHZcBmoCF6/FV3v6PrW7XjMLOFwLnu/s8Onq8D4939vY6a1szGAAuAYnev74h2irSkKNcNEOkM7l4eD7cUAmZWpC9b2VHo73HHoK5UyStmNt3MPjSz75pZBXCLmfU3s4fNbJWZrYuGRyRe87SZnRsNn2Vmz5nZtdG0C8zsmDZOO9bMnjGzTWb2TzP7tZndnqXdrWnjlWb2fDS/J8xsUOL5081skZmtMbPvt7B+pppZhZkVJsadYGZvRMMHmdmLZrbezJab2a/MrEeWed1qZj9OPP529JplZnZOs2mPM7PXzGyjmS0xsysSTz8T3a83s0ozOyRet4nXH2pmM81sQ3R/aGvXzXau5wFmdku0DOvM7MHEc8eb2exoGd43s6Oj8Wnd1mZ2Rfw5m9mYqEv5y2a2GHgqGn9P9DlsiP5GJiReX2pmP4s+zw3R31ipmT1iZhc1W543zOyETMsq2SkYJR8NAwYAo4HzCP8Ht0SPRwE1wK9aeP1U4G1gEPBT4I9mZm2Y9i/Ay8BA4Arg9BbeszVt/CJwNjAE6AF8C8DM9gF+G81/1+j9RpCBu78EVAGHN5vvX6LhBuCb0fIcAhwBXNBCu4nacHTUnk8C44Hm2zergDOAfsBxwPlm9tnouWnRfT93L3f3F5vNewDwCPCLaNmuAx4xs4HNlmGrdZPBttbznwld8xOieV0fteEg4E/At6NlmAYszLY+MjgM2Bs4Knr8GGE9DQFeBZJd/9cCBwCHEv6OvwM0ArcBX4onMrNJwHDCupHt4e666datb4QvqCOj4elAHVDSwvSTgXWJx08TumIBzgLeSzxXBjgwbHumJXzp1gNliedvB25v5TJlauNliccXAI9Hw/8D/DXxXK9oHRyZZd4/Bm6OhnsTQmt0lmkvBh5IPHZg92j4VuDH0fDNwDWJ6fZITpthvjcA10fDY6JpixLPnwU8Fw2fDrzc7PUvAmdta91sz3oGdiEEUP8M0/0ubm9Lf3/R4yvizzmxbLu10IZ+0TR9CcFdA0zKMF0JsI6w3RZCgP6mq//fusNNFaPko1XuXhs/MLMyM/td1DW1kdB11y/ZndhMRTzg7tXRYPl2TrsrsDYxDmBJtga3so0VieHqRJt2Tc7b3auANdnei1AdnmhmPYETgVfdfVHUjj2i7sWKqB1XE6rHbUlrA7Co2fJNNbN/R12YG4CvtXK+8bwXNRu3iFAtxbKtmzTbWM8jCZ/ZugwvHQm838r2ZtK0bsys0MyuibpjN5KqPAdFt5JM7xX9Td8FfMnMCoBTCRWubCcFo+Sj5rti/19gT2Cqu/ch1XWXrXu0IywHBphZWWLcyBamb08blyfnHb3nwGwTu/t8QrAcQ3o3KoQu2bcIVUkf4NK2tIFQMSf9BXgIGOnufYEbE/Pd1q7zywhdn0mjgKWtaFdzLa3nJYTPrF+G1y0BxmWZZxWhtyA2LMM0yWX8InA8obu5L6GqjNuwGqht4b1uA04jdHFXe7NuZ2kdBaNI6C6sIezcMQD4QWe/YVSBvQJcYWY9zOwQ4NOd1MZ7gf8ys49FO8r8iG3/7/8F+AYhGO5p1o6NQKWZ7QWc38o23A2cZWb7RMHcvP29CdVYbbS97ouJ51YRujB3yzLvR4E9zOyLZlZkZqcA+wAPt7JtzduRcT27+3LCtr/fRDvpFJtZHJx/BM42syPMrMDMhkfrB2A28IVo+inAya1ow2ZCVV9GqMrjNjQSuqWvM7Ndo+rykKi6JwrCRuBnqFpsMwWjSNieVUr4NT4DeLyL3vc0wg4sawjb9e4ifCFm0uY2uvs84EJC2C0nbIf6cBsvu5OwQ8hT7r46Mf5bhNDaBNwUtbk1bXgsWoangPei+6QLgB+Z2SbCNtG7E6+tBq4CnrewN+zBzea9BvgvQrW3hrAzyn81a3drbWs9nw5sIVTNKwnbWHH3lwk791wPbAD+Q6qKvZxQ4a0Dfkh6BZ7JnwgV+1JgftSOpG8Bc4CZwFrgJ6R/l/8J2JewzVraQAf4i+wgzOwu4C137/SKVbovMzsDOM/dP5brtuysVDGK5IiZHWhm46Kut6MJ25Ue3NbrRLKJuqkvAH6f67bszBSMIrkzjHAoQSXhGLzz3f21nLZIdlpmdhRhe+wKtt1dKy1QV6qIiEiCKkYREZEEnUS8Gxg0aJCPGTMm180QEdmpzJo1a7W7D24+XsHYDYwZM4ZXXnkl180QEdmpmFnzMyYB6koVERFJo2AUERFJUDCKiIgkKBhFREQSFIwiIiIJLQZjdH20o5qNu9jMftvCa56OziCPmT2a6RItZnaFmWW7gnY8zWejK4/Hj39kZs2v+t1mZnaDmS2NrlsmIiICbLtivBP4QrNxX4jGb5O7H+vu69vSMOCzhEvHxPP6H3f/ZxvnlSYKwxMI11A7rCPmmeV9dDiMiMhOZltf3PcCPzazHu5eZ2ZjCFfLfjaqGg8kXKLl3kxXBDCzhcAUd19tZt8HziRcqmUJMCua5ivAeUAPwuVoTgcmA58BDjOzy4CTCJduedjd7zWzI4Bro/bPJJxjcnP0frcRrmtXDHzO3d/KsFzTgXmES+acCvw7astQwgVS4+u+ne/uL0Rnq/8W4WKib7j76WZ2a9ye6LWV7l5uZtOBKwmXmNmLcJ24BwkXaS0Bfu7uv49eczThWmuFhMvcfBJ4GzjU3VdFAf4OcIi7r8r6Ke3sXnwRHnsMBg+Gr34VevTIPN3f/w4zZ2Z+buhQ+MhHoLYWXn0Vqqq2vx39+8Nuu8HcubA529WfOkFhIXz5yzBiRGrcokUwfDg8/TS4w8EHw003wfjxMHAgvP02LFiwfe/Tvz985Stw330wYQJMmZL+/D/+Ac8/3+7F2RGtrOpFcUED/UtrO3y+PQvr6VuS+ntZvKEvg8uqKC2u32r65ZvKKSpoZHCv6rTxdQ2FfLCuP7sPWEtRQWPT+EY3PtzYh1F9N7S7rR+s68+ovhsoKmhkTXUp97+1D2d8ZDY9ixoA2FxfyJMfjOPDTX340r5vUN6jrt3v2SUuvxyKizt0li0Go7uvNbOXCVfy/huhWrzb3d3Mvh89Xwj8y8w+4u5vZJqPmR0QvXZy9J6vEgUjcL+73xRN92Pgy+7+SzN7iPTgiedVAtwKHOHu75jZnwgXS70hmt9qd9/fzC4ghNm5GZp0KqHq/RtwtZkVu/sWwomc/+PuJ0TLVW5mE4DLCGG1Orp46bbsD0x09/ib65xoXZUCM83sPkK1fhMwzd0XmNkAd280s9sJ1+m7gXAF79czhaKZnUf4QcGoUc0vhr4D2bIl/Y+2sRHq61Phd8MN8H/+T/jyhxCQ990HpaWwdi088wyMGwf33ANXXhmmsWYXjM90vt/m07RGcj5teX1bucPy5XDjjeHxm2/CxIkwaBCsXBmCc/JkmDVr69dG7XzZD2Qc71NKDXOZyEEWfkDUek9e5BBKqeFgZsBll0F1dZjnr38dfohA+NHx2c9CYyOOsZme9KCOq7mUg5nBAsbyXa6hB3Vcwk9YzSCqKeNQXqAf6/kLX6SSXnyc5yijmpeYygHM4iBe5kNGsIrBjOBDjuSfFJizxEfwNX5LJeXcxHmM512e4FPsx2sMsVX8zs/jV1zIA5zION7nQn7N7ZzGLiznGr6H4XyU55nBwTzO0UzhFYaygh9wBVso5nRuZzKzuZBf0Y/1vMIUitnCKdzF3rzFLPbnJabSn3UUs4V32INSariYn/MIx/I6kwAooZYpvMJBzORfHM7rTGpqwyJGcxnfYRCr+Tz3cDefYygreJmpHMIL/IsjqaMHd3EKz/IxnuejLGA3Sqnm93yVOnrwElPpx3oe4VjmMZE+bODHXM5YFlDMFm7iXO7jZG7lLIazlCLqOZCZ1FPEDA7mMP7DTXyFBYxlPf14kONppIB9mcOhvMhHeZ4CGrmOb/JvDudMbuVmvswXeZQnOIpbHhlMFb0YzlKWMJK57AvA/Y+WUE8RFQzjUF5kPO8yj32opoz57EMdPTiEFzmImfQi/AidzGxeYQrX8F2O4XH+wzQKaeAcbuFz3MPFXM8rTOEcbuH7XMUc9uVGvsYxPMaLHMK+zKEf63mKw/k8dzOUFbzOJJ7no3zAWAaylv/LzziLWxjLAn7IFZRQyy7fuxTr4GDE3Vu8Eb6k74yGZwMHRMNfIwTcG4Qzun8hGv80oUoEWAgMIlzM80eJeV4HfCsaPgx4lnDhzQXAjdH4W4GTE6+5lXDl60nAM4nxRxDCNX6/4dHwVOCfGZanB+ECoL2jx/cTLmpKtBw9m01/EXBVhvk0b19ldD8d+Hezaa8AXo9uG4CDCVXtHRnmOxJ4NRr+a9y2lm4HHHCA75B+/nP3/v3d33rLfc4c99NOc+/b133oUPctW8I0o0a5f+xj7ps2uf/+9+7gfuWV4bmzzgqP49upp7rX1W39Po2N7gsXuv/jH+5PPeW+dm3b2rtsmftzz7lv3Ni217fVaaeF9VRbGx5fe21Y3qOOcr/0UvePfCQ8/s1vQvsef9x93jzfsrnBn302rC5wP+kk969+NQw/8kiY1WGHhcfFxe6v3DjTfdo0v/srT/hbE050nzgxTLRxo3t5ufuUKX77H2t80CD3oiL3ww8Pry0tDa8/5BD36dPDuMJC95KS1EfTr5/72LGpx+Xl6R9dfBs50n38eHcz97Ky8LoePdwnTw7PDx7sfuyxqekPPND9qqvC8Iknuu+5Z+q5/v3DfIqL0+f/0Y+m2rjbbqHd3/ym+5e/HF4D4c/ulFPcjzwyLNNFF7l/4hPhuYED3b/+9fCac85x32efMH7MmDA+2Ybp00Obwf2II9ynTg2vMQvv0bt3eG7o0ND+a69132+/9PVWXOy+yy7h3+WTn9x6nY0fn/64qCisu7it8edbWup+5pnuF1wQ2pFcL8OHu3/602F46tRwf8opYR3tv7/7kCGhDffd5/7LX4bnBwwIn0W8zoYPd997b/fjjnM/4YSwTJk+43HjwvIfeGBY9+C+667uvXqlPpvp08NXQabXN78VF4d13qNHaG9RUbjFz9fUtP1fD3jFM+VeppFpE0A5oftzf+CdaNxYQrdnf0+FxFnR8PYG4wJgUjR8FnBrYp5tCcZB0fAU4OkMy/NpoCqadmG0bHdEz21PMP4B+Hw0XADURcPTCZUuicfPAWWJ9TM9WzBG0zwGHA58ABRu6zPaIYNx1qzUf+ZBB4Vv0fLyEILgPn++e0NDmOa730297thjw3/7Bx+E/4TPf979T39yf+21EICRmprwZbZ0aecuxksvuX/nO2lv3fEeeyysk/vvD4+POip8A3lYTU89sN7vuHSuDxvm/rWvuf/61+G3xo03pr4c4jDr1SsVMM8+G4Yvvth9xAj33XcPywPuUwe/F76t3L3u/r/7RN7wH531vg8aFELq5JPDdGeeGcJl+HD31avDevjnP8PHs3mz+4wZ7vfc415VlVpfzzwTpnv3Xfc77wztWLjQ/Y473D/3uTDvH/7Q/f33w+d3wQWhbVdeGb4499gj/En89a+p5TviiPDnUl3tfu+94bfBIYeEeVVWus+bF9qxfn1478svd993X/dFi9JXdUOD+5o1mT+Gxkb3hx92X7586+c2bnSvrw/DcRviP8mFC8PvsaTbbw/hce657jNnpv/9bNwYPur4X6CmJvU7sbEx/Dk884z7k0+6v/ii+7p17uef7/6Xv4T2XXpp+Dv4wx9CaP7gB+GziD+DWHV1mM+DD4bnt2wJ/17jx4f109gY2tLYGJ5raEi99sknU+sh2zprbAy/JRctCn8PP/uZ+/e+F367VlWF5+vrQyAXFoblamx0v/pq9wkT3A8+OKyDBx5w//DD8MPghz90r6hwv+228Dv5mWfCcri7/+c/4e/kjjvC7+zf/S7c4nXXFm0OxvBa7iJUiz+MHk+Kqp8CYCjh+l8tBeP+hMqyFOgNvJsIxtXAEMI2wScTwfhL4OxEG+JgLAEWA7snxn8j+X7ecjD+BTg18bhXFI5lhArt4mh8IdAXmEDYzjcwGj8gur8M+Ek0/FkgWs9bBePxwN+j4b2A2miawYRtrWOT842GTwKWxfPf1m2HC8bGRvcpU8IX78UXe9PPyIqK8G0C7nff7b5yZRj+xS9Sr33hhTBuxIhw/+abGd/in/8MT//v/2ZuQkWF+xtvpL7MWvLnP4cv7+bq68M/MIScf/vt9F+nmze7X3/91l++rdHYGG6zZ3v4zx482P3008MblJa6f/3rXlMTqo44HPbYI/xWgPAr/5OfTIXd/Pmp6W66KXwRxdXEkiXuTz8dfsXHwfmpMW+FHyvu/uHZl6X9Qn/++dDGt98OX4obN4ZQzIU33wyfzebNuXl/ab8tW9r2P9IV2huMnyXseLJXYtytUWD8i9AdmTUYo+HvR9M/F4VTHIznE6rGl6MwjIPxo8B84DVgHIkKklAlvkbofr2ZqMrbVjBG4bcW6NNs/P3AKYSQ/1s039mEnV4g7DQ0l/BjIG7fUGBGNO4npHelJoOxJ6ECfJNwdfangenRc8dEy/E68GTiNcXAxuT6bum2wwXj3XeHP61bbgk/5y+5JJQP7uGLv6DA/X/+JxWS996b/vorrwx9J2eemfUt4t7Gk04KvyiTgTV3bqqbZsIE91Wrsjf1e98L002atPVzf/xjKiyOOy40e+rU0PRLLgm/VuMupnnzWrdqGhvDYn3606me42ef9dDvdMwx7v/6Vxj59783LeMll4RbTU1YnT/9aRhvFqrZ2BFHhOVobAwVBoQKLHbZZYnl2evdMFBV5a+N+WzT+E99qnXLIdIdtCsYdevaWxTqz7Z2+h0qGOvrQ2kzcWL2cm3PPUM/0yOPhD/BF19scZZbtoTtP7/5TWrcaad5U2HZv394S/ewCW7EiLC95Je/dO/ZMxSre+0VwmjGjNQ8Zs5MBcWBB279vp/4RFiMT30qTNOnT5hf/JrS0rD9adiwsD0mOe+GhlAAXnttarVcdVXoKopfH1d/11zjYWPgYYc1pe3cf1V4nz6hV7W5tWtT2/deeCE1fuPG0O3mHirmIUPcb745fT3ecUco5j+2+/KmGTzBkQ7ujz7avu01IjsbBeNOcgMuARYBH2vta3aoYLzzTs9YBSadfHLY0BGXTNvoZ1m0KBUm3/526FaLuziTt/nzQ1U3dmzURelhW87kySEUhw4NYVFREZ770pfCzhHHHRfCs7kxY0IAx5XjtdeGyvDtt0NxB+5/+1vYVrbbbmFHivnzw2t/8pPw/D77hMezZqXaOWmS+7RpYbi8PFS9fuyxIbGuu84rKfNRIxp82LDsq+bcc91Hj07fLtRctu2ixx/v/pHR60IDrrzS7+DUlnqtRbotBWM3vu0wwdjYGPZ42Hvvlr+xr7gi9AN+97vhT3AbG5BmzAiTxdvbDj44bENL7sFnFrI43h6YyZw5odI6+uiww0RxcdjL8KKLQtdrXV2o6CZODPMoLHT//vdD8/785/QdYtevD6EYh8+CBSF4BwwI7YtDzyxMGxfHl18egnTlyrAzwimnhOXyk08OKXrllf4iU5s2w2ZTW5uqDrfXGWe4jx5aExr0+c/7DXzdIXfbEUVyJVsw6nRo0nEWLIA5c+DCC6GghT+tiRNDnj3+OAwZkv2A/sjy5eH+gQfg9tthxgxoaICzz4aSkvBcr16wIToGeuDA7G/7s5+Ftz3ggPC23/hGOK/Ahg3wpz/BD34Qju+/+ebwHqNHh+m+9KX0wzH79oXPfCZ1uOOYMfDkk3DkkeHcAFdfHdrqHs5JUFERpjvnnHAOgcGD4eijwzH2ixfDShsaTkpQVcWHhWMA2GOP7OukZ0/ot9XJFlunb1/YUB0dwjxnDqsYQmGh079/2+Yn0t3olGXScWbPDvcHHdTydB//eLh//fVw4Po2xKEybBjsv38Ixl//Gg49NJys5Y474Pe/hzVrwnR9+2af1/nnhwD7+9/hoYdCSA0aFJ576aWQ54MGwSOPhHFjxmyzeU323Rfuuiv1eH10MsQZM1K/E4YNS3/NgQeG+5lV+3Bc9d1QVcWS4t2gAUaObP17b4++fWFjVSEO2DvvsKpsFAPLrcXfMiL5RP8K0nFeey0kwMSJWz110UXw4IPRgyFDmhLhyR7HZTyhS9Ly5aEyGzIkPL7hhlDVjR4N06bB3nuH8R9+GKbr0yf7vMxCeL39Nhx7bBgXB+Ps2SG4Jk2ChQvDuO0Jxub69Qtte+mlEO79+qUq3Nh++4X7ORtHhzPSVFWxpHAMpaV0WgXXty80NhqVlENDA6t6jGDw4M55L5GdkYJROs7s2bDXXuF0bs386ldwwgmJEVEqff2dC/nmN1ue7fLlIRSLov6NwkLYZ5/U83EQLl4MvXu33IsLoWt03LjU4zgY58wJpyudMCH1XHvPtnfQQamu1ObVYtz2Xr1g5Zb+IRgrK/nQRjJyZOedlS5eXxtKQoNWFQxRMIokKBil48yenSqBEtwzTBsF47otvZk5E2pqQjAlVVfDe+9lD5VY3HW6eHHbtrvFoVBbG87bHQfjLruEbXntMXEirFgB8+ZlX4YhQ2Dl5r5hRa1Zw5LG4Z3WjQqp9bWhT3iTVY0DFYwiCQpG6RirV4e+zAzbDLdsSQ0vXRoNTJkC3/kOGxvKqK2FM88MXZhvJa6F8t//HS4m8c47IaSyiSugRYta3r6YTVwxQnrF2J5u1FjczTt/fvZgHDoUVtT05gk+yVVzj2dJ/bC0C210tKZg7B3eZNXmPgpGkQQFo3SM118P9xmCMXkFp6arRhUUsOXHP6GmNvwJ3nNPKJgeeGDrWb79dsvBGH/Rr1nTtooxuRfriBGpMOuIYEx2+WZbhiFDwuWL/sC5XL7iQpbVDeqSinFj2TDqKWRtTZmCUSRBwSgdI94jddKkplHusGpV6KKMvfxyanjTpvRZ9OiR2EEnfVatCsbmw61VXJx63YgRIVy/8IVwOEZ7jR6d2uTaYldqZRmLGYVTgFPQNRVj6VDWEH4VKBhFUhSM0jFeey1soEt8w95/fzjkYNmy1GTJ6wzHxx326gUDBsC3vx2CM54+ufNJS9sYk3uhtvXYvrjZcSDdeWcIx/YqKIA99wzDLQXjqo09WciYpnFdso2xxxBWERZcwSiSomCUjjF79lbdqG+8EbpRP/wwPC4uDodZLF8OJ50UtgkC/PznITDjvVbji8jX1KTm1ZkVI6S2Mw4f3rbXtyTuTm1pG2NDYwErGEYPQr9zZwZj016pRQNZTVhwBaNIioJR2q+mJuw102yP1Dj44gPd998/7GF6222hmnzqqTB+9OhwoH28ra8qXBCc6urUvHbfPfvbl5amDuVoa8XYmcEYb7NsaRtj7Dv8lAsnPcdee3V8O2Ll5aGS3TD6I1Qe8/mmcSISKBil/ebNC+dPa1YxLl4c7tetC/f77x/u//zncP/+++E+rmDig9/jSrG6Gg45BN58s+UT5CQP6m9rxbjrriG4mh+A3xFOOCFsrxw/PvPzyWCcztP86jNPpJ1+rqPF62tD7xHUnnMBkPHQU5G8pWCU9nv11XDfLL3iijEOxgMOCPfz54f7OBjjMIu/nOOddaqroayMVlVP8TzaWjFecQU8+mjbXrstEybA3/6WPXSHDk0Nj2Jx2Ojayfr2Ddt44x8hnfGDQGRnpXOlSvusXw9XXRVOJTN2bNPoxkZYsiQMx8E4fnzosqusDI9bUzEOGNC6ZsTB2NaKcZddWt6O2ZmSFeNIluQkGFUxiqSoYpT2ufTScNT+7bennYutoiJ1YH+8jbG0NP24vtWrw30cjD16hG6+uGKsqWn9F3Y8j7ZWjLk0YAAUFDhDqaCEzaFM7mQKRpHsFIzSPrNmweGHw8EHp42Oty9CqmIsKUmdVSYuigoLUzlgFqZJVoytzYj2Voy5VFgYdv4ZRbTSuqBi7NMHNm5M/QhRMIqkqCtV2qeiIuNGwHj7IqQH40knwcqV4Uv52WfDF3TyeMXS0q23MbZGe7cx5treexvjV80Bp0uCsaws/ACJf4S095ywIt2JKkZpO/dwhuwMB+hlqxiPOw4efji1Xa35JaLaWjG2d6/UXHv0UfhV+SXhQRcEY69e4bCYmpoQiroWo0iK/h2k7TZsCEfwJ3erjCxalNqZJg7GZFUSH1CeKRhra0Pmbs82xp25KxXCD4Ce5dExGl1UMVZXb986FskX6kqVtluxItxnqRjHjw+XkkpWjLH4gPrmwVhaGr6sN28O4djaivGUU8LOOzv1YQfxwnZRxahgFMlMwShtV1ER7rNUjKNHw7vvpg7PSIZWXDE2r/DiijE+601rg3HSpPSTju+U4kDswm2M1dU7+Y8JkU6grlRpuzgYs1SMyStLmJF2NpdsXalxxbi9wdgtxAvbBQsdv8XataoYRZpTMErbxV2pzSrGjRvDsYvJYCwpSd/7NFtXalwx5uXxdV3clQrhGpZ5tY5FWkHBKG1XURHO3t3s9DTxHqmjRqW+dJsfDqCKMYM4rbogqeL1qmAU2ZqCUdpuxYpQLTbb1z8+hrF5xZjU0dsYu4WysnDrgmMn4gxevVrbGEWaUzBK21VUZNzxJlPF2PzLd+hQOOYYmDYtfXzeV4xddP2neL1u3KiKUaQ57ZUqbVdRkXHHm0WLwo42w4ZlD8aiosxXs8jriqiZI78AABQBSURBVPGii+BTn+qSt0quVwWjSDoFo7TdihUZj5FYvDhcgb6gIPs2xmziijEvd76ZPLnlC092oOT+PXm1jkVaQV2p0jYNDaFibHatpoceghdfDNsXIXvFmE1eV4xdKLletY1RJJ2CUdpm+fIQjiNHNo2qrITjjw/Hxp18chi3vcFYWgp1dbBpU3isYOwcqhhFslMwSpvUvLc0DIwa1TQurvKuvhouuCAMt6VihNRp5BSMnUPbGEWyUzDKdquogH6fnMJ/mJZWMW7eHO6T2xPbUjFCqDqTj6VjKRhFslMwynarqIC6+kLeZO+MwdijR2ra7d35Jg7QtWvDfAoLO6DBshVtYxTJTsEo223LlnC/useuaUfo19WF+46oGNesUTdqZyoqSv2AUcUokk7BKNstDsDVvcaknQC1I7pSkxWjgrFzdeEZ6ER2KgpGab2rr4Zp01LBWDI87emO3saoL+zOFf/wUFeqSDoFo7TevffCs8+yZWHYI3V1Qfrp4FQx7lxUMYpkpmCU1qmshNdfB6DumRkArPH+aZO0FIzbc+YbCMHYBVdfymvxDw8Fo0g6BaO0zksvQWMjFBay5ZEnAFhdl37NqJb2St3eirGxEcaMaUd7ZZsUjCKZKRildV54Iexoc8YZ1K1aD8DqmlDSNTaGc5t25F6pALvv3t5GS0viilzbGEXSKRildZ5/HiZMgMsuo+7wowGorCqgthZuvBHGjg3nOIWO2cYICsbOpopRJDMFo2zbhg3w9NNw+OGw225sOe3spqfWrIFZs8KFNjZuDOM6YhsjKBg7m3a+EclMwSjbdu+9YQPiaacBqS5TCFeAX7QoDK8PPayqGHcSqhhFMlMwyrbdfjvssQcceCCQOvMNhIqxpWDcfXc47LCml25T/CVdXg5DhrSz3dIiHccokpmCUVq2dm3oRj311Kaz3CQrxpUrw4WJIRWMyb1Se/cOL99jj9a9XRyqu++edlId6QTqShXJTMEoLZs7N9wffHDTqGQwzpuXepypYtxeZqGCGTeu7fOQ1hk3DoYOVTCKNKdglJbNmRPuJ05sGpXsSp01KzW8YUMItqKi9r3lYYfBUUe1bx6ybWefHbrBdQUTkXTt/AqTbm/u3HAFjeGp86LW1YUv0yFD4LnnUpOuXx+qxfZ2gT7+ePteL61TUNC+6l6ku1LFKC2bOxf23Tct7erqoLgYTjwRNm1KTbpunb5oRWTnp2CU7NxDMCa6USF0pfboAV/6UvrkccUoIrIzUzBKdkuXhrTbd9+00XV1IRinToXx41N7N65fn75HqojIzkjBKNm9+Wa432eftNFbtoSuVDO46y649dYwvq5OFaOI7Py0841kt2xZuB85Mm10XDEC7LcfjBiRek7BKCI7O1WMkl1FRbgfmn5B4mQwQvpxcApGEdnZKRglu4oKKC/nrw+Xs2pVanTclRpTMIpId6JglOwqKtgweHdOPRVuuy01unnFWFiYeqydb0RkZ6dglOwqKqgaNBpIne4Ntq4YYfsvLyUisqNSMEp2FRXUDAx71sTXWoStK0ZQMIpI96FglOwqKqjutyugYBSR/KFglMxqa2H9emr67QKkB6O6UkWkO1MwSmYrVgBQ0yccqqGKUUTyhYJRMouOYazuNRgIl5SKtVQxaq9UEdnZKRglsygYa8oGAqoYRSR/KBgls+XLAaju2R9QMIpI/lAwSmbLl4MZNcW9Ae18IyL5QycRl8yWLIFddqGmLvyJVFfDHXfAa6+pYhSR7k3BKJktXgyjRlFdnRr1hz/AG29AY6OCUUS6L3WlylZWrIBlH9TCqFHU1KTGv/lm2Du1rk57pYpI96VglK2MH+8MX/DcVsG4YgU0NIRuVVWMItJdKRhlK5s2GQCr+u+R1pWapJ1vRKS7UjBKVk+vn5xWMSapYhSR7krBKFvZa3g4NuPfC8dkrRgVjCLSXSkYZSsNdQ0A/Ht2f2pqYODAradRV6qIdFcKRtlK3H361rtFrF8Pw4ZtPU22ilF7pYrIzk7BKFuprSuggFA1LlkCgweDWfo0zSvGsrJwr4pRRHZ2CkbZSm1DMSN6rgJCMJaVQe/e0KdPaprmleG++4bbnnt2YUNFRDqBglG2UtvYg5Elq4FwXtSyshCKe+2VmqZ5MI4ZE86Kk6nbVURkZ6JglDT19VDvRYwoW9s0rrQUdtsNJk2C8vIwrnlXqohId6FzpUqa2tpwP7J8XdO4sjJ4+GEoKoJHHoHKSu1kIyLdlypGSRMH4669U9eZKi0N2xhLS6Fv3zBOwSgi3ZWCUdLEwdi7tJ7+4RrFTYdiQCoY1ZUqIt2VglHSxMFYUmIMHhyG40MxILVnqipGEemuFIySJj64v6QEBg0Kw6oYRSSfKBglTapizByMqhhFpLvTXqmSprbGAaO0zBgUVYXJrlTtfCMi3Z0qRklTu2kLACVlqW2M6koVkXyiYJQ0NRvjYCxUV6qI5CUFo6RJVYwFTcGY7EqdPBlGjqSpmhQR6W60jVHS1FaFq2qU9i5il13CuLj7FGD6dFi8uOvbJSLSVVQxSpraynoASnoVcuSRcN99MGVKjhslItKFVDFKmprKUDGWlBdRWAgnnpjjBomIdDFVjJIm7kotKddvJhHJTwpGSVNb0whASR/tdioi+UnBKGlqqxvpwWYKSnvmuikiIjmhYJQ0NdVQQm04J5yISB5SMEqa2hoPwdhTFaOI5CcFo6SprVXFKCL5TcEoaWproZQaVYwikrcUjJKmZrOpYhSRvKZglDS1cTCqYhSRPKVglDS1dQUKRhHJawpGSVNbV6BtjCKS1xSMkqamrpASq4MC/WmISH7St5+kqd1SSEnhllw3Q0QkZxSMkqa2vkjBKCJ5TcEoaWrriygtUjCKSP5SMEqamvpiSorqc90MEZGcUTBKE3eoqu9JeY/NuW6KiEjOKBilSU0NOAX0KlZXqojkLwWjNKmsDPflPRWMIpK/FIzSpKoq3PfqqW2MIpK/FIzSpKliLFEwikj+UjBKk6aKsbQxtw0REckhBaM0aaoYSxty2xARkRxSMEqTpoqxzHPbEBGRHFIwSpOmirGXglFE8peCUZo0VYy9ctsOEZFcUjBKk6aKsbfltiEiIjmkYJQmVZVhb9RefQpz3BIRkdwpynUDZMdRtaGBntRR1KtnrpsiIpIzqhilSeWGBnpRBSUluW6KiEjOKBilSdWmBsqphNLSXDdFRCRnFIzSpHKjh4pRwSgieUzBKE2qKl0Vo4jkPQWjNKmsdG1jFJG8p2CUJlXVpopRRPKeglGaVFYVaBujiOQ9BaM0qaotUMUoInlPwShNKmsKtY1RRPKeglEAcIeqzUWqGEUk7ykYBYC6Oqhv0DZGEREFowCpS06VU6muVBHJawpGAVKXnFLFKCL5TsEoQCIYrQaKi3PbGBGRHFIwCgBr14b7gT03gelCxSKSvxSMAsDq1eF+UM/K3DZERCTHFIwCwJo14X5gaXVuGyIikmMKRgESFWOvmtw2REQkxxSMAoRgLC3cTFlZrlsiIpJbCkYBQjAOKt6gQzVEJO8pGAWIgrFovYJRRPKeglGAKBgL1ioYRSTvKRgFCHulDrK1Oh2ciOQ9BaMAoWIc6KtVMYpI3lMwCvX1sG4dDPJVCkYRyXsKRmk6HdyghhUKRhHJewpGSR3cv2W5tjGKSN5TMEoiGJepYhSRvKdglFQwop1vREQUjMKqVeF+EKvVlSoieU/BKCxbBmbOULTzjYiIglFYuhSGDmqgiAYFo4jkPQWjsGwZDB9cFx7o8hoikucUjMLSpbBr2YbwYOzY3DZGRCTHFIwSKsaC5eHBXnvltjEiIjmmYMxzmzeHwzV2rf0ARo6E3r1z3SQRkZxSMOa55VGhOHzDfNh779w2RkRkB6BgzHNLF9UDsGvFqwpGEREUjPnLHQ47jGVX3QLA8M3vKxhFRFAw5i8zGDKEpS8tAWBXlikYRURQMOa1xk8fz9yNo+hpmxlQtAn23TfXTRIRybmiXDdAcqOhAaZe9wVmUcRR/jh29lnQv3+umyUiknOqGPNUYSGccloRt+99FX+34+G73811k0REdgiqGPPYt78NHHksvLM7jBuX6+aIiOwQFIz5br/9wk1ERAB1pYqIiKRRMIqIiCQoGEVERBIUjCIiIgkKRhERkQQFo4iISIKCUUREJEHBKCIikqBgFBERSVAwioiIJCgYRUREEhSMIiIiCQpGERGRBAWjiIhIgoJRREQkQcEoIiKSoGAUERFJUDCKiIgkKBhFREQSFIwiIiIJCkYREZEEBaOIiEhChwSjmQ00s9nRrcLMliYe99jGa6eY2S9a8R4vdERbE/O7IWqnfhyIiEiToo6YibuvASYDmNkVQKW7Xxs/b2ZF7l6f5bWvAK+04j0O7Yi2Ru0pAE4AlgCHAf/uqHk3e5+syy0iIjumTquWzOxWM7vRzF4CfmpmB5nZi2b2mpm9YGZ7RtNNN7OHo+ErzOxmM3vazD4ws68n5leZmP5pM7vXzN4yszvMzKLnjo3GzTKzX8TzzWA6MA/4LXBq4j2GmtkDZvZ6dDs0Gn+Gmb0RjftzYvlOztK+Z83sIWB+NO7BqE3zzOy8xGuONrNXo/n+y8wKzOxdMxscPV9gZu/Fj0VEpPN1SMXYghHAoe7eYGZ9gI+7e72ZHQlcDZyU4TV7AZ8AegNvm9lv3X1Ls2n2AyYAy4DngY+a2SvA74Bp7r7AzO5soV2nAncCfwOuNrPi6D1+AfzH3U8ws0Kg3MwmAJdFy7HazAa0Yrn3Bya6+4Lo8TnuvtbMSoGZZnYf4UfJTYn2DnD3RjO7HTgNuAE4Enjd3Vc1f4MoYM8DGDVqVCuaJCIirdHZ29fucfeGaLgvcI+ZzQWuJwRbJo+4+2Z3Xw2sBIZmmOZld//Q3RuB2cAYQqB+kAijjMEYbfM8FnjQ3TcCLwFHRU8fTqgicfcGd98Qjbsnag/uvrYVy/1yoh0AXzez14EZwEhgPHAw8Ew8XWK+NwNnRMPnALdkegN3/727T3H3KYMHq6AUEekonV0xViWGrwT+HVVjY4Cns7xmc2K4gcxtbM002RwF9APmRD2wZUANkK3bNZt6oh8W0TbL5E5GTcttZtMJld8h7l5tZk8DJdlm6u5LzGyFmR0OHESoHkVEpIt05R6ZfYGl0fBZnTD/t4HdotAFOCXLdKcC57r7GHcfA4wFPmlmZcC/gPMBzKzQzPoCTwGfM7OB0fi4K3UhcEA0/BmgOMv79QXWRaG4F6FShFA9TjOzsc3mC/AH4HbSK24REekCXRmMPwX+n5m9RidUqu5eA1wAPG5ms4BNwIbkNFH4HQ08knhdFfAc8GngG8AnzGwOMAvYx93nAVcB/4m6Q6+LXnoTcFg07hDSq+Okx4EiM3sTuIYQiETbDc8D7o/mcVfiNQ8B5WTpRhURkc5j7p7rNnQYMyt398poL9VfA++6+/W5btf2MrMpwPXu/vHWTD9lyhR/5ZVtHvEiIiIJZjbL3ac0H9/dDm7/ipnNJhyK0Zewl+pOxcwuAe4DvpfrtoiI5KNuVTHmK1WMIiLbL18qRhERkXZRMIqIiCSoK7UbMLNVwKI2vnwQsLoDm7Mz0DLnBy1z/mjrco92963OkKJgzHNm9kqmPvbuTMucH7TM+aOjl1tdqSIiIgkKRhERkQQFo/w+1w3IAS1zftAy548OXW5tYxQREUlQxSgiIpKgYBQREUlQMOYpMzvazN42s/ei87N2W2a20MzmmNlsM3slGjfAzJ40s3ej+/65bmd7mNnNZrYyuhB4PC7jMlrwi+izf8PM9s9dy9suyzJfYWZLo896tpkdm3jue9Eyv21mR2We647NzEaa2b/NbL6ZzTOzb0Tju+1n3cIyd95n7e665dkNKATeB3YjXGD5dcIltnLetk5a3oXAoGbjfgpcEg1fAvwk1+1s5zJOA/YH5m5rGYFjgccAI1wf9KVct78Dl/kK4FsZpt0n+jvvSbgG6/tAYa6XoQ3LvAuwfzTcG3gnWrZu+1m3sMyd9lmrYsxPBwHvufsH7l4H/BU4Psdt6mrHA7dFw7cBn81hW9rN3Z8B1jYbnW0Zjwf+5MEMoJ+Z7dI1Le04WZY5m+OBv7r7ZndfALxH+D/Yqbj7cnd/NRreBLwJDKcbf9YtLHM27f6sFYz5aTiwJPH4Q1r+Q9vZOfCEmc0ys/OicUPdfXk0XAEMzU3TOlW2Zezun/9/R92GNye6yLvdMpvZGGA/4CXy5LNutszQSZ+1glHywcfcfX/gGOBCM5uWfNJD/0u3Pm4pH5Yx8ltgHDAZWA78LLfN6RxmVk64buvF7r4x+Vx3/awzLHOnfdYKxvy0FBiZeDwiGtctufvS6H4l8AChW2VF3KUU3a/MXQs7TbZl7Lafv7uvcPcGd28EbiLVhdZtltnMigkBcYe73x+N7tafdaZl7szPWsGYn2YC481srJn1AL4APJTjNnUKM+tlZr3jYeBTwFzC8p4ZTXYm8LfctLBTZVvGh4Azoj0WDwY2JLrhdmrNtp+dQPisISzzF8ysp5mNBcYDL3d1+9rLzAz4I/Cmu1+XeKrbftbZlrkzP+ui9jVZdkbuXm9m/w38g7CH6s3uPi/HzeosQ4EHwv8WRcBf3P1xM5sJ3G1mXyZcsuvzOWxju5nZncB0YJCZfQj8ALiGzMv4KGFvxfeAauDsLm9wB8iyzNPNbDKhK3Eh8FUAd59nZncD84F64EJ3b8hFu9vpo8DpwBwzmx2Nu5Tu/VlnW+ZTO+uz1inhREREEtSVKiIikqBgFBERSVAwioiIJCgYRUREEhSMIiIiCQpGERGRBAWjiIhIwv8HEisZdVI+7mMAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoyJwWu6SB-6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "799f25d4-d69c-476d-8402-1243380d5922"
      },
      "source": [
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.figure()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXvD91jF-peP",
        "outputId": "a3f0ba67-2381-4b62-88e9-e7478bf669ac"
      },
      "source": [
        "generator= train_datagen.flow_from_directory('/content/drive/MyDrive/dataset/Traindata', batch_size=10)\n",
        "label_map = (generator.class_indices)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 700 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Cfc9Kjg-rgK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c17bd3ff-9c75-4d2b-8925-6fe92c575e50"
      },
      "source": [
        "label_map"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'10': 0, '100': 1, '1000': 2, '20': 3, '50': 4, '500': 5, '5000': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBfyRcA78Znw",
        "outputId": "32fee02c-541c-42dd-cf73-2f3e997f06ae"
      },
      "source": [
        "image = keras.preprocessing.image\n",
        "model = keras.models.load_model('/content/drive/MyDrive/Currency/CurrencyDetectionModel.h5')\n",
        "#path to any image to be predicted\n",
        "path = '/content/drive/MyDrive/train/10/10B1_0_1349.jpeg'\n",
        "dim = (256,256)\n",
        "img = image.load_img(path,target_size=(256,256))\n",
        "#img = cv2.imread(path, cv2.IMREAD_UNCHANGED) \n",
        "#resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "#img = np.array(resized,dtype='float32')/255\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "#[x] can be an array of images \n",
        "#images = np.vstack([x])\n",
        "#classes = model.predict_class(x)\n",
        "predict = model.predict(x)\n",
        "predict = np.argmax(predict,axis=1)\n",
        "print(predict)\n",
        "# Desired output. Charts with training and validation metrics. No crash :)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa78dde6dd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7fa78dde6dd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45aLMaz0P1b3",
        "outputId": "ef1032c9-a434-42bc-e324-d339766ea3b2"
      },
      "source": [
        "predict"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks3bFLSBAajJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce598a4a-ab75-4448-f8b9-8231779d0d7d"
      },
      "source": [
        "if predict == 0:\n",
        "  n = '10 Rupees'\n",
        "  print(n)\n",
        "elif predict == 1:\n",
        " n = '100 Rupees'\n",
        " print(n) \n",
        "elif predict == 2:\n",
        "   n = '1000 Rupees'\n",
        "   print(n)\n",
        "elif predict == 3:\n",
        "  n = '20 Rupees'\n",
        "  print(n)\n",
        "elif predict == 4:\n",
        "  n = '50 Rupees'\n",
        "  print(n)\n",
        "elif predict == 5:\n",
        "  n = '500 Rupees'\n",
        "  print(n)\n",
        "elif predict == 6:\n",
        "  n = '5000 Rupees'\n",
        "  print(n)          "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 Rupees\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "id": "pTr_ZdZKvz_Q",
        "outputId": "95a3c3eb-3f89-4262-9ec5-23828771bdca"
      },
      "source": [
        "tts = gTTS(n) #Provide the string to convert to speech\n",
        "tts.save('1.wav') #save the string converted to speech as a .wav file\n",
        "sound_file = '1.wav'\n",
        "Audio(sound_file, autoplay=True)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Currency/CurrencyDetectionModel.h5')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "open(\"CurrencyDetection.tflite\", \"wb\").write(tflite_model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsvgIoM2QIrn",
        "outputId": "f739a55e-901a-4488-ab7a-6a3a67be57c6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp2rfzl3x5/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118081204"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/CurrencyDetection.tflite /content/drive/MyDrive/Currency"
      ],
      "metadata": {
        "id": "xUlKxpBmQjXb"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}